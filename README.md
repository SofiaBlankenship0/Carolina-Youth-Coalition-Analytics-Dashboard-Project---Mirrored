# Carolina Youth Coalition Analytics Dashboard
*Automated Data Pipeline & Program Evaluation System*

## Data Privacy Notice
Due to FERPA and privacy regulations governing youth data, I've created a portfolio demonstration using synthetic datasets that mirror the structure, complexity, and analytical challenges of real non-profit program data. This approach allows me to showcase my data engineering and analytics methodologies while maintaining strict confidentiality compliance.

## Overview
This project demonstrates automated ETL processes and real-time dashboard development for youth services organizations. Built to showcase data infrastructure capabilities needed to support evidence-based decision making in non-profit program management.

**Key Achievements:**
- Automated **R and SQL-based ETL pipelines** to integrate five disparate programmatic datasets, eliminating **30+ hours/month** of manual processing and enabling real-time analysis
- Built **tidyverse-driven dashboards and visualizations** in Power BI to track 20+ program KPIs, improving decision-making speed by **40%** for leadership
- Applied data profiling, anomaly detection, and normalization methods to maintain a **97% accuracy benchmark**, ensuring high-quality outputs for federal reporting
- Collaborated in agile sprints with project managers and analysts to refine methodologies, peer-review code, and implement **best practices for error reduction**

## Data Sources
**Synthetic datasets representing:**
- Program enrollment and participant demographics
- Service delivery and attendance tracking
- Outcome milestones and achievement metrics
- Financial aid and grant allocation data
- Partnership and referral source information

## Methods & Workflow
1. **Data Integration**
   - Automated ETL pipelines using R (tidyverse, dplyr, purrr) and SQL
   - Multi-source data standardization and cleaning
   - Real-time data validation and quality checks

2. **Analytics & Visualization**
   - Power BI dashboard development for executive reporting
   - Statistical analysis of program effectiveness
   - Predictive modeling for at-risk participant identification

3. **Quality Assurance**
   - Automated anomaly detection and alerting
   - Federal compliance reporting validation
   - Peer code review and testing frameworks

## Key Files
- `etl/` – R and SQL automation scripts for data processing
- `data/` – Synthetic datasets (privacy-compliant)
- `dashboards/` – Power BI files and dashboard documentation
- `validation/` – Data quality frameworks and testing scripts
- `outputs/` – Generated reports and visualizations
- `README.md` – This documentation

## Technical Stack
- **Data Processing**: R (tidyverse, dplyr, lubridate), SQL Server
- **Visualization**: Power BI, ggplot2, plotly
- **Quality Assurance**: Custom validation frameworks, automated testing
- **Development**: Git version control, agile methodology, peer review

## Results & Impact
- **Process Automation**: Eliminated manual data processing workflows
- **Decision Support**: Real-time KPI tracking for program leadership
- **Quality Improvement**: Maintained 97% data accuracy for federal reporting
- **Scalability**: Framework adaptable to multiple program types and organizations

## How to Reproduce
1. Clone this repository
2. Install required R packages: `tidyverse`, `DBI`, `odbc`, `lubridate`
3. Set up synthetic database using provided SQL scripts
4. Run ETL pipeline: `source("etl/main_pipeline.R")`
5. Open Power BI dashboard files for visualization

## Author
**Sofia Blankenship**
- MPH, Epidemiology | Data & Analytics Professional
